# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Yuni is a programming language compiler implemented in Rust with LLVM backend. The language combines memory safety (Rust-style ownership), high performance (LLVM optimization), and expressive features like pattern matching and algebraic data types.

## Essential Development Commands

### Building
```bash
# Development build
cargo build

# Release build (optimized)
cargo build --release
```

### Testing
```bash
# Run all tests
cargo test

# Run specific test
cargo test test_println_builtin
```

### Code Quality
```bash
# Format code
cargo fmt

# Lint code
cargo clippy

# Generate documentation
cargo doc --open
```

### Using the Compiler
```bash
# Compile Yuni source to executable
cargo run -- compile examples/hello.yuni

# Run Yuni program directly (JIT)
cargo run -- run examples/hello.yuni

# Check syntax only
cargo run -- check examples/hello.yuni


# Compile with optimization
cargo run -- compile examples/hello.yuni -O3

# Emit LLVM IR instead of executable
cargo run -- compile examples/hello.yuni --emit llvm-ir

# Emit object file
cargo run -- compile examples/hello.yuni --emit obj

# Verbose compilation
cargo run -- compile examples/hello.yuni --verbose
```

## Architecture Overview

The compiler follows a traditional multi-stage pipeline:

**Lexer** (`src/lexer/`) → **Parser** (`src/parser/`) → **AST** (`src/ast/`) → **Analyzer** (`src/analyzer/`) → **CodeGen** (`src/codegen/`) → **Runtime** (`src/runtime/`)

### Key Components

- **Main CLI** (`src/main.rs`): Command-line interface with compile/run/check subcommands
- **Lexer** (`src/lexer/`): Tokenization using the `logos` crate
- **Parser** (`src/parser/`): Recursive descent parser using `nom` combinators, produces AST
- **AST** (`src/ast/`): Abstract syntax tree definitions with serde support for dumping
- **Analyzer** (`src/analyzer/`): Semantic analysis including type checking and ownership validation
- **CodeGen** (`src/codegen/`): LLVM code generation using `inkwell` bindings
- **Runtime** (`src/runtime/`): Runtime support functions (C implementation)

### Compilation Pipeline

1. **Lexical Analysis**: Source code → Tokens (with error reporting)
2. **Parsing**: Tokens → AST (with position tracking for diagnostics)
3. **Semantic Analysis**: AST validation, type checking, ownership analysis
4. **Code Generation**: AST → LLVM IR using inkwell
5. **Linking**: LLVM IR + runtime.c → executable (via clang)

## Dependencies

### LLVM 18 Requirement
The project requires LLVM 18. The build script (`build.rs`) automatically detects LLVM installation:
- macOS: Uses Homebrew paths (`/opt/homebrew/opt/llvm@18/`)
- Linux: Uses system packages (`llvm-18-dev`)
- Manual: Set `LLVM_SYS_180_PREFIX` environment variable

### Key Rust Dependencies
- **inkwell**: Safe LLVM bindings for code generation
- **logos**: Fast lexer generator
- **nom**: Parser combinator library
- **clap**: CLI argument parsing with subcommands
- **codespan-reporting**: Beautiful error diagnostics
- **anyhow/thiserror**: Error handling

## Testing Strategy

Tests are located in `tests/` directory. The main test file `println_test.rs` demonstrates the full compilation pipeline from source to codegen for the built-in println function.

Test pattern: Lex → Parse → Analyze → CodeGen for various language features.

## Important Notes

- The runtime is implemented in C (`src/runtime.c`) and linked with generated code
- Error reporting uses codespan for beautiful diagnostics with source code context
- The compiler supports multiple output formats: executable, LLVM IR, object files, assembly
- Optimization levels 0-3 are supported and passed through to LLVM

## Documentation Guidelines

**All documentation in this project should be written in Japanese.** This includes:

- Code comments and docstrings (use `/// ` for Rust doc comments)
- README files and markdown documentation
- Error messages and user-facing text
- Commit messages
- API documentation generated by `cargo doc`
- Language specification documents in `docs/` directory

When creating or updating documentation:
- Use clear, technical Japanese appropriate for software documentation
- Include both Japanese explanations and code examples
- Maintain consistency with existing Japanese documentation style in the project
- For language features, provide examples in both Japanese comments and Yuni code